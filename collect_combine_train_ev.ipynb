{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the combination you want to try \n",
    "combination = '11B,3B'\n",
    "\n",
    "# base directory where the extracted features stored  in models named directory\n",
    "models_base_directory = \"features_timing\" \n",
    "\n",
    "# targeting the individual features (we want to target)\n",
    "features_base_directory = f\"features/features({combination})\"\n",
    "\n",
    "# Define the base directories for features and combined features\n",
    "base_combined_directory = f\"combined_features/combined_features({combination})\"\n",
    "\n",
    "# Select the model's name according to the combination you're trying for\n",
    "model_names = [\n",
    "    \"Llama-3.2-3B\", \n",
    "    # \"Llama-3.2-3B-Instruct\", \n",
    "    \"Llama-3.2-11B-Vision\", \n",
    "    # \"Llama-3.2-11B-Vision-Instruct\"\n",
    "]\n",
    "\n",
    "# define directory where you want to store the checkpoints\n",
    "checkpoint_dir = f'checkpoints/checkpoints({combination})'\n",
    "\n",
    "# defined directory to store the evaluation (csv) file\n",
    "results_directory = 'evaluation'\n",
    "\n",
    "# evaluation file name\n",
    "evaluation_file = f'checkpoints({combination})_100'\n",
    "\n",
    "# combined_dir = base_combined_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your feature data\n",
    "train_machine_path = f'{base_combined_directory}/train/machine/combined_train_machine_features.npy'\n",
    "train_human_path = f'{base_combined_directory}/train/human/combined_train_human_features.npy'\n",
    "dev_machine_path = f'{base_combined_directory}/dev/machine/combined_dev_machine_features.npy'\n",
    "dev_human_path = f'{base_combined_directory}/dev/human/combined_dev_human_features.npy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying feature's files from timing model's f`iles and create combinations of individual features in featured directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: Llama-3.2-3B for scenario: train/human\n",
      "Copied Llama-3.2-3B_features(label0_train2).npy from Llama-3.2-3B to features/features(11B,3B)/train/human/Llama-3.2-3B_train_human.npy\n",
      "Processing model: Llama-3.2-11B-Vision for scenario: train/human\n",
      "Copied Llama-3.2-11B-Vision_features(label0_train2).npy from Llama-3.2-11B-Vision to features/features(11B,3B)/train/human/Llama-3.2-11B-Vision_train_human.npy\n",
      "Processing model: Llama-3.2-3B for scenario: train/machine\n",
      "Copied Llama-3.2-3B_features(label1_train3).npy from Llama-3.2-3B to features/features(11B,3B)/train/machine/Llama-3.2-3B_train_machine.npy\n",
      "Processing model: Llama-3.2-11B-Vision for scenario: train/machine\n",
      "Copied Llama-3.2-11B-Vision_features(label1_train3).npy from Llama-3.2-11B-Vision to features/features(11B,3B)/train/machine/Llama-3.2-11B-Vision_train_machine.npy\n",
      "Processing model: Llama-3.2-3B for scenario: dev/human\n",
      "Copied Llama-3.2-3B_features(label0_dev2).npy from Llama-3.2-3B to features/features(11B,3B)/dev/human/Llama-3.2-3B_dev_human.npy\n",
      "Processing model: Llama-3.2-11B-Vision for scenario: dev/human\n",
      "Copied Llama-3.2-11B-Vision_features(label0_dev2).npy from Llama-3.2-11B-Vision to features/features(11B,3B)/dev/human/Llama-3.2-11B-Vision_dev_human.npy\n",
      "Processing model: Llama-3.2-3B for scenario: dev/machine\n",
      "Copied Llama-3.2-3B_features(label1_dev3).npy from Llama-3.2-3B to features/features(11B,3B)/dev/machine/Llama-3.2-3B_dev_machine.npy\n",
      "Processing model: Llama-3.2-11B-Vision for scenario: dev/machine\n",
      "Copied Llama-3.2-11B-Vision_features(label1_dev3).npy from Llama-3.2-11B-Vision to features/features(11B,3B)/dev/machine/Llama-3.2-11B-Vision_dev_machine.npy\n",
      "Feature extraction and copying completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# combination = '3B+11B'\n",
    "# # Define the base directories\n",
    "# models_base_directory = \"timing\"  # Base directory where model folders are located\n",
    "# features_base_directory = f\"features/features({combination})\"  # Directory where you want to store features\n",
    "\n",
    "# # Define the base directories for features and combined features\n",
    "# base_combined_directory = f\"combined_features/combined_features({combination})\"\n",
    "\n",
    "# # List of models to process\n",
    "# model_names = [\n",
    "#     \"Llama-3.2-3B\", \n",
    "#     \"Llama-3.2-3B-Instruct\", \n",
    "#     \"Llama-3.2-11B-Vision\", \n",
    "#     \"Llama-3.2-11B-Vision-Instruct\"\n",
    "# ]\n",
    "\n",
    "# Scenarios to loop through (dev/train and human/machine)\n",
    "scenarios = [\n",
    "    (\"train\", \"human\"),\n",
    "    (\"train\", \"machine\"),\n",
    "    (\"dev\", \"human\"),\n",
    "    (\"dev\", \"machine\")\n",
    "]\n",
    "\n",
    "# Iterate through each scenario\n",
    "for scenario in scenarios:\n",
    "    split, category = scenario\n",
    "    \n",
    "    # Create scenario-specific directories in the features_base_directory\n",
    "    destination_scenario_directory = os.path.join(features_base_directory, split, category)\n",
    "    os.makedirs(destination_scenario_directory, exist_ok=True)\n",
    "    \n",
    "    # Iterate through each model in the list\n",
    "    for model_name in model_names:\n",
    "        print(f\"Processing model: {model_name} for scenario: {split}/{category}\")\n",
    "        \n",
    "        # Define the source directory for the current model and scenario\n",
    "        source_directory = os.path.join(models_base_directory, model_name, split, category)\n",
    "        \n",
    "        # List all .npy files in the source directory and move them to the destination\n",
    "        for file_name in os.listdir(source_directory):\n",
    "            if file_name.endswith('.npy'):\n",
    "                source_file_path = os.path.join(source_directory, file_name)\n",
    "                \n",
    "                # Define the new file name in the format: model_name_scenario.npy\n",
    "                new_file_name = f\"{model_name}_{split}_{category}.npy\"\n",
    "                destination_file_path = os.path.join(destination_scenario_directory, new_file_name)\n",
    "                \n",
    "                # Copy the feature file to the destination and rename it\n",
    "                shutil.copy(source_file_path, destination_file_path)\n",
    "                print(f\"Copied {file_name} from {model_name} to {destination_file_path}\")\n",
    "\n",
    "print(\"Feature extraction and copying completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the features stored in the features directory for specified combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---features_directory ----- features/features(11B,3B)/train/human\n",
      "Processing file: Llama-3.2-11B-Vision_train_human.npy for train/human\n",
      "-------file_path------- features/features(11B,3B)/train/human/Llama-3.2-11B-Vision_train_human.npy\n",
      "Shape of array 0: (228922, 127, 3)\n",
      "Processing file: Llama-3.2-3B_train_human.npy for train/human\n",
      "-------file_path------- features/features(11B,3B)/train/human/Llama-3.2-3B_train_human.npy\n",
      "Shape of array 0: (228922, 127, 3)\n",
      "Shape of array 1: (228922, 127, 3)\n",
      "Combined features saved to 'combined_features/combined_features(11B,3B)/train/human/combined_train_human_features.npy'.\n",
      "---features_directory ----- features/features(11B,3B)/train/machine\n",
      "Processing file: Llama-3.2-3B_train_machine.npy for train/machine\n",
      "-------file_path------- features/features(11B,3B)/train/machine/Llama-3.2-3B_train_machine.npy\n",
      "Shape of array 0: (381845, 127, 3)\n",
      "Processing file: Llama-3.2-11B-Vision_train_machine.npy for train/machine\n",
      "-------file_path------- features/features(11B,3B)/train/machine/Llama-3.2-11B-Vision_train_machine.npy\n",
      "Shape of array 0: (381845, 127, 3)\n",
      "Shape of array 1: (381845, 127, 3)\n",
      "Combined features saved to 'combined_features/combined_features(11B,3B)/train/machine/combined_train_machine_features.npy'.\n",
      "---features_directory ----- features/features(11B,3B)/dev/human\n",
      "Processing file: Llama-3.2-11B-Vision_dev_human.npy for dev/human\n",
      "-------file_path------- features/features(11B,3B)/dev/human/Llama-3.2-11B-Vision_dev_human.npy\n",
      "Shape of array 0: (98328, 127, 3)\n",
      "Processing file: Llama-3.2-3B_dev_human.npy for dev/human\n",
      "-------file_path------- features/features(11B,3B)/dev/human/Llama-3.2-3B_dev_human.npy\n",
      "Shape of array 0: (98328, 127, 3)\n",
      "Shape of array 1: (98328, 127, 3)\n",
      "Combined features saved to 'combined_features/combined_features(11B,3B)/dev/human/combined_dev_human_features.npy'.\n",
      "---features_directory ----- features/features(11B,3B)/dev/machine\n",
      "Processing file: Llama-3.2-3B_dev_machine.npy for dev/machine\n",
      "-------file_path------- features/features(11B,3B)/dev/machine/Llama-3.2-3B_dev_machine.npy\n",
      "Shape of array 0: (163430, 127, 3)\n",
      "Processing file: Llama-3.2-11B-Vision_dev_machine.npy for dev/machine\n",
      "-------file_path------- features/features(11B,3B)/dev/machine/Llama-3.2-11B-Vision_dev_machine.npy\n",
      "Shape of array 0: (163430, 127, 3)\n",
      "Shape of array 1: (163430, 127, 3)\n",
      "Combined features saved to 'combined_features/combined_features(11B,3B)/dev/machine/combined_dev_machine_features.npy'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directories for features and combined features\n",
    "# features_base_directory = \"features/features(3B+11B)\"\n",
    "# base_combined_directory = \"combined_features/combined_features(3B+11B)\"\n",
    "\n",
    "# Scenarios to loop through\n",
    "scenarios = [\n",
    "    (\"train\", \"human\"),\n",
    "    (\"train\", \"machine\"),\n",
    "    (\"dev\", \"human\"),\n",
    "    (\"dev\", \"machine\")\n",
    "]\n",
    "\n",
    "# Loop through each scenario and process the files\n",
    "for scenario in scenarios:\n",
    "    split, category = scenario\n",
    "\n",
    "    # Define the directories based on the scenario\n",
    "    features_directory = os.path.join(features_base_directory, split, category)\n",
    "    print('---features_directory -----', features_directory)\n",
    "    combined_features_directory = os.path.join(base_combined_directory, split, category)\n",
    "    os.makedirs(combined_features_directory, exist_ok=True)\n",
    "    # List all the .npy files in the directory\n",
    "    features_list = []\n",
    "    for file_name in os.listdir(features_directory):\n",
    "        if file_name.endswith('.npy'):\n",
    "            # Load each .npy file and append it to the features_list\n",
    "            print(f\"Processing file: {file_name} for {split}/{category}\")\n",
    "            file_path = os.path.join(features_directory, file_name)\n",
    "            print('-------file_path-------', file_path)\n",
    "            features_list.append(np.load(file_path))\n",
    "            for i, feature in enumerate(features_list):\n",
    "                print(f\"Shape of array {i}: {feature.shape}\")\n",
    "\n",
    "\n",
    "    # Combine features along a new axis (e.g., axis=2)\n",
    "    combined_features = np.concatenate(features_list, axis=2)\n",
    "\n",
    "    # Create the directory to save the combined features if it doesn't exist\n",
    "    os.makedirs(combined_features_directory, exist_ok=True)\n",
    "\n",
    "    # Define the combined file name based on the scenario\n",
    "    combined_file_name = f\"combined_{split}_{category}_features.npy\"\n",
    "    combined_file_path = os.path.join(combined_features_directory, combined_file_name)\n",
    "\n",
    "    # Save the combined features\n",
    "    np.save(combined_file_path, combined_features)\n",
    "\n",
    "    print(f\"Combined features saved to '{combined_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLMIXTIC model using PyTorch. This model consists of a Transformer encoder.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LLMIXTIC(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(LLMIXTIC, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 128)  # Project to 128 dimensions\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=128, nhead=4), num_layers=1\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc(x))  # Linear layer followed by ReLU\n",
    "        x = self.transformer_encoder(x)  # Transformer Encodertrain_texts\n",
    "        x = x.mean(dim=1)  # Average pooling\n",
    "        return self.classifier(x)  # Classifier layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# combined_dir = f'combined_features/combined_features({combination})'\n",
    "# checkpoint_dir = f'checkpoints/checkpoints({combination})_test'\n",
    "# evaluation_file = f'checkpoints({combination})_test_vishnu'\n",
    "\n",
    "# dev_combined_dir = f'combined_features/combined_features({combination})'\n",
    "\n",
    "# # Define paths to your feature data\n",
    "# train_machine_path = f'{combined_dir}/train/machine/combined_train_machine_features.npy'\n",
    "# train_human_path = f'{combined_dir}/train/human/combined_train_human_features.npy'\n",
    "# dev_machine_path = f'{combined_dir}/dev/machine/combined_dev_machine_features.npy'\n",
    "# dev_human_path = f'{combined_dir}/dev/human/combined_dev_human_features.npy'\n",
    "\n",
    "# Load training and dev features\n",
    "train_machine_features = np.load(train_machine_path)\n",
    "train_human_features = np.load(train_human_path)\n",
    "\n",
    "dev_machine_features = np.load(dev_machine_path)      # Label 1 for machine-generated\n",
    "dev_human_features = np.load(dev_human_path )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "# Create labels for the training and dev sets\n",
    "train_machine_labels = np.ones(train_machine_features.shape[0])  # Label 1 for machine-generated\n",
    "train_human_labels = np.zeros(train_human_features.shape[0])     # Label 0 for human-generated\n",
    "\n",
    "dev_machine_labels = np.ones(dev_machine_features.shape[0])      # Label 1 for machine-generated\n",
    "dev_human_labels = np.zeros(dev_human_features.shape[0])         # Label 0 for human-generated\n",
    "\n",
    "# Combine the features and labels\n",
    "train_features = np.concatenate([train_machine_features, train_human_features], axis=0)\n",
    "train_labels = np.concatenate([train_machine_labels, train_human_labels], axis=0)\n",
    "\n",
    "dev_features = np.concatenate([dev_machine_features, dev_human_features], axis=0)\n",
    "dev_labels = np.concatenate([dev_machine_labels, dev_human_labels], axis=0)\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_features_tensor = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "dev_features_tensor = torch.tensor(dev_features, dtype=torch.float32)\n",
    "dev_labels_tensor = torch.tensor(dev_labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "dev_dataset = TensorDataset(dev_features_tensor, dev_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32  # Define your batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cair-iai/miniconda3/envs/sem_pipeline/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch [1/5]: 100%|██████████| 19087/19087 [00:34<00:00, 548.77batch/s, loss=0.0136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.0925\n",
      "Checkpoint saved: checkpoints/checkpoints(11B,3B)/epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: 100%|██████████| 19087/19087 [00:34<00:00, 551.89batch/s, loss=0.000762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.0358\n",
      "Checkpoint saved: checkpoints/checkpoints(11B,3B)/epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: 100%|██████████| 19087/19087 [00:34<00:00, 550.98batch/s, loss=0.00502] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.0249\n",
      "Checkpoint saved: checkpoints/checkpoints(11B,3B)/epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: 100%|██████████| 19087/19087 [00:34<00:00, 558.16batch/s, loss=0.0385]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.0186\n",
      "Checkpoint saved: checkpoints/checkpoints(11B,3B)/epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: 100%|██████████| 19087/19087 [00:34<00:00, 551.52batch/s, loss=0.00119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.0149\n",
      "Checkpoint saved: checkpoints/checkpoints(11B,3B)/epoch_5.pth\n",
      "Model saved to llmixtic_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Assume train_features is defined\n",
    "input_dim = train_features.shape[-1]  # Input dimension from the feature size\n",
    "model = LLMIXTIC(input_dim)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist\n",
    "checkpoint_dir = f'{checkpoint_dir}'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Training loop with checkpoints and progress bar\n",
    "num_epochs = 5\n",
    "checkpoint_interval = 1  # Save a checkpoint every epoch\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "        for inputs, labels in tepoch:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save model checkpoint after every epoch\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch+1}.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# Final model saving\n",
    "model_save_path = 'llmixtic_model_final.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import os\n",
    "import pandas as pd  # Import pandas for handling CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting a specific checkpoint\n",
    "# checkpoint_file = f'{checkpoint_dir}/epoch_5.pth'\n",
    "# # Load the checkpoint \n",
    "# checkpoint = torch.load(checkpoint_file, weights_only=True)\n",
    "\n",
    "# # Print the keys in the checkpoint\n",
    "# print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cair-iai/miniconda3/envs/sem_pipeline/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLMIXTIC(\n",
       "  (fc): Linear(in_features=6, out_features=128, bias=True)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the model and load the state_dict from checkpoint\n",
    "input_dim = train_features.shape[-1]  # Input dimension should be same as during training\n",
    "model = LLMIXTIC(input_dim)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to the specified device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Uncomment when using a stored checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])  # Uncomment when using a stored checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0  # Track total number of correct predictions\n",
    "    total = 0    # Track total number of samples\n",
    "\n",
    "    # Training loop with checkpoints and progress bar\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move the inputs and labels to the GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Calculate accuracy and track correct outputs\n",
    "            total += labels.size(0)\n",
    "            batch_correct = (predicted == labels).sum().item()\n",
    "            correct += batch_correct  # Accumulate correct predictions\n",
    "\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Dev Accuracy: 98.89%, Total Correct Outputs: 258846/261758\n",
      "Epoch 2 - Dev Accuracy: 99.24%, Total Correct Outputs: 259779/261758\n",
      "Epoch 3 - Dev Accuracy: 99.35%, Total Correct Outputs: 260047/261758\n",
      "Epoch 4 - Dev Accuracy: 99.26%, Total Correct Outputs: 259811/261758\n",
      "Epoch 5 - Dev Accuracy: 99.67%, Total Correct Outputs: 260903/261758\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['epoch_no', 'num_inputs_processed', 'num_correct_outputs', 'accuracy'])\n",
    "\n",
    "num_epochs = 5\n",
    "checkpoint_interval = 1  # Save a checkpoint every epoch\n",
    "\n",
    "# List to store results for each epoch\n",
    "results = []\n",
    "\n",
    "# Evaluate the model loaded from checkpoint on the dev dataset\n",
    "for epoch in range(1, num_epochs + 1):  # Assuming num_epochs is defined\n",
    "    # Load the checkpoint for the current epoch\n",
    "    checkpoint_file = f'{checkpoint_dir}/epoch_{epoch}.pth'\n",
    "    checkpoint = torch.load(checkpoint_file, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # Load the model state_dict\n",
    "\n",
    "    # Evaluate the model\n",
    "    dev_accuracy, correct_outputs, total_samples = evaluate_model(model, dev_loader)\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({\n",
    "        'epoch_no': epoch,\n",
    "        'num_inputs_processed': total_samples,\n",
    "        'num_correct_outputs': correct_outputs,\n",
    "        'accuracy': dev_accuracy\n",
    "    })\n",
    "\n",
    "    # Print results for the current epoch\n",
    "    print(f\"Epoch {epoch} - Dev Accuracy: {dev_accuracy:.2f}%, Total Correct Outputs: {correct_outputs}/{total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to evaluation/checkpoints(11B,3B)_100.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create the evaluation directory if it doesn't exist\n",
    "# results_directory = 'evaluation'\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_csv_path = f'{results_directory}/{evaluation_file}.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Evaluation results saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
